{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mt9dL5dIir8X"
   },
   "source": [
    "##### Copyright 2020 The TensorFlow Authors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hoQQiZDB6URn"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "# import pandas\n",
    "# import shutil \n",
    "# import os\n",
    "# import numpy as np\n",
    "# import glob\n",
    "# import pathlib\n",
    "# import tensorflow as tf\n",
    "# import random\n",
    "# import codecs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # choose some random files names from some folders\n",
    "# print(random.choice(os.listdir(\"Merged_dataset/001\")))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Random Samples of Each Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# main_dir = 'Merged_dataset/'\n",
    "# data_dir = pathlib.Path(main_dir)\n",
    "# print(data_dir)\n",
    "# Class = np.array(sorted([item.name for item in data_dir.glob('*') if item.name != \"LICENSE.txt\"]))\n",
    "# class_names = []\n",
    "\n",
    "# for i in Class:\n",
    "#     if i not in class_names:\n",
    "#         class_names.append(i)\n",
    "\n",
    "# NUM_CLASSES = len(class_names)\n",
    "\n",
    "# dataSets = [tf.data.Dataset for x in range(NUM_CLASSES)]\n",
    "# dir = []\n",
    "# image_count_train = np.zeros(NUM_CLASSES)\n",
    "\n",
    "# for i in range(NUM_CLASSES):\n",
    "#   temp = str(class_names[i]+'/*')\n",
    "#   dir.append(str(data_dir/temp))\n",
    "#   print(dir)\n",
    "#   dataSets[i] = (tf.data.Dataset.list_files(dir, shuffle=False))\n",
    "#   dir = []\n",
    "#   image_count_train[i] = len(dataSets[i])\n",
    "\n",
    "# print(class_names)\n",
    "\n",
    "\n",
    "# for c in class_names:\n",
    "#   if not os.path.exists(str('testDataset/' + c)):\n",
    "#     os.makedirs(os.path.join(str('testDataset/' + c)))\n",
    "#     print(\"created path for class\", c)\n",
    "\n",
    "\n",
    "# duplicates=[]\n",
    "# for i in range(len(class_names)):\n",
    "#   for f in range(int(image_count_train[i]*0.2)):\n",
    "\n",
    "#     random_file =random.choice(os.listdir(\"Merged_dataset/\"+class_names[i]))\n",
    "#     while(random_file in duplicates):\n",
    "#       random_file =random.choice(os.listdir(\"Merged_dataset/\"+class_names[i]))\n",
    "\n",
    "#     if random_file not in duplicates:\n",
    "#       duplicates.append(random_file)\n",
    "#     else:\n",
    "#       print(\"file already exists for class\"+ class_names[i])\n",
    "    \n",
    "#     img_path='Merged_dataset/'+class_names[i]+'/'+ random_file\n",
    "#     shutil.move( img_path, str('testDataset/' + class_names[i] + '/'))\n",
    "#     print(img_path, \"copied to\", str('testDataset/' + class_names[i] + '/'))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import csv\n",
    "# import pandas\n",
    "\n",
    "# filename ='i2.csv' # the dir of the csv file\n",
    "# sorted_csv=pandas.read_csv(filename)\n",
    "# # sorted_csv = csv_file.sort_values(by=['Label'])\n",
    "\n",
    "# filename2 ='i1.csv' # the dir of the csv file\n",
    "# sorted_csv2=pandas.read_csv(filename2)\n",
    "# # sorted_csv2 = csv_file2.sort_values(by=['id'])\n",
    "\n",
    "  \n",
    "# # print(sorted_csv[0:5]['Image_ID'])\n",
    "# # print(sorted_csv2.iloc[828]['filename'])\n",
    "# found=[[],[],[]]\n",
    "# classes=[0,1,2]\n",
    "\n",
    "# # print(sorted_csv.iloc[0]['Image_ID']+'.JPG',sorted_csv2.iloc[829-3]['filename'])\n",
    "\n",
    "# # convert the csv file to a list of lists\n",
    "\n",
    "\n",
    "\n",
    "# s2=sorted_csv2['Image_ID'][826].split('.')[0]\n",
    "\n",
    "# print(s2, sorted_csv['Image_ID'][0] )\n",
    "# # print(s[829-3] in s )\n",
    "# for i in  range(len(sorted_csv)):\n",
    "#   label=sorted_csv.iloc[i]['Label']\n",
    "#   image_id=sorted_csv.iloc[i]['Image_ID']+'.JPG'\n",
    "#   # print(image_id,sorted_csv2['filename'][0])\n",
    "#   # x=input()\n",
    "#   if image_id in sorted_csv2['filename']:\n",
    "#     print(image_id, \"found in both\")\n",
    "#     if image_id not in found[label]:\n",
    "#       found[label].append(i)\n",
    "#       print(i,'added to the list!')\n",
    "#     else:\n",
    "#       print('found in the list!')\n",
    "\n",
    "# for j in found:\n",
    "#   print(len(j))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging The Datasets And Export Them To Single CSV File "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # \n",
    "# import csv\n",
    "# import pandas\n",
    "# # import shutil \n",
    "\n",
    "# class_names = [1,2,3] # label of the photos classes  001 --> road, 002--> bump, 003--> pothole\n",
    "# sub_dirs = ['D:/GP/New version/Merged_dataset/New folder/','D:/GP/New version/Merged_dataset/New folder/','D:/GP/New version/Merged_dataset/New folder/'] # each one of the subdirs is one of the two folder you have after splitting/cleaning the data\n",
    "# filename ='D:/GP/New version/Merged_dataset/images.csv' # the dir of the csv file\n",
    "# csv_file0=pandas.read_csv(filename)\n",
    "# sorted_csv0 = csv_file0.sort_values(by=['id'])\n",
    "# # class_names0 = list(sorted_csv0['id'].unique())\n",
    "\n",
    "\n",
    "# ##########newest dataset file ############\n",
    "# csv_file=pandas.read_csv('D:/GP/New version/NEWEST_DATASET_BUMPS/NEWEST_DATASET_BUMPS.csv')\n",
    "# sorted_csv = csv_file.sort_values(by=['id'])\n",
    "# # class_names = list(sorted_csv['id'].unique())\n",
    "# # print(class_names)\n",
    "# # print(sorted_csv[0:10])\n",
    "# ##########train dataset file ############\n",
    "# csv_file1=pandas.read_csv('D:/GP/New version/train/image.csv')\n",
    "# sorted_csv1 = csv_file1.sort_values(by=['id'])\n",
    "# # class_names1 = list(sorted_csv1['id'].unique())\n",
    "# # print(class_names1)\n",
    "# # print(sorted_csv1[0:10])\n",
    "\n",
    "# dataset_dir='D:/GP/New version/test/'\n",
    "\n",
    "# if not os.path.exists(dataset_dir+'001') or not os.path.exists(dataset_dir+'002')or not os.path.exists(dataset_dir+'003'):\n",
    "#   os.makedirs(os.path.join(dataset_dir+'NEWEST_DATASET_BUMPS/'+'001'))\n",
    "#   os.makedirs(os.path.join(dataset_dir+'NEWEST_DATASET_BUMPS/'+'002'))\n",
    "#   os.makedirs(os.path.join(dataset_dir+'NEWEST_DATASET_BUMPS/'+'003'))\n",
    "  \n",
    "#   os.makedirs(os.path.join(dataset_dir+'train/'+'001'))\n",
    "#   os.makedirs(os.path.join(dataset_dir+'train/'+'002'))\n",
    "#   os.makedirs(os.path.join(dataset_dir+'train/'+'003'))\n",
    "#   print(\"created\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# data_locs=sub_dirs[0:3]#[\"D:/GP/New version/PotHole/001/roads/\",\"D:/GP/New version/PotHole/001/bumps/\"]\n",
    "# print(data_locs)\n",
    "# filename1=dataset_dir+'train_test.csv'\n",
    "# temp2=''\n",
    "# with open(filename1, 'w', newline='') as writeFile:\n",
    "#   writer = csv.writer(writeFile)\n",
    "#   writer.writerow(['filename','id','dataset'])\n",
    "#   for i in class_names:\n",
    "#     temp='00'+str(i)          \n",
    "#     for c in list(sorted_csv0[sorted_csv0['id']== i]['filename']):    # c  ->  individual image \n",
    "#     # Creating path to the image\n",
    "#       print(c)\n",
    "#       if c in list(csv_file['filename']):\n",
    "#         print(\"entered for \",c)\n",
    "#         writer.writerow([c,temp,'NEWEST_DATASET_BUMPS'])\n",
    "#         temp2='NEWEST_DATASET_BUMPS/'\n",
    "      \n",
    "#       if c in list(csv_file1['filename']):  \n",
    "#         print(\"entered for \",c)\n",
    "#         writer.writerow([c,temp,'train'])\n",
    "#         temp2='train/'\n",
    "\n",
    "#       if c in list(csv_file['filename']) or c in list(csv_file1['filename']):\n",
    "#         get_image = os.path.join(data_locs[i-1],c)\n",
    "#         print(get_image)\n",
    "#         # # get_image to that path\n",
    "#         if os.path.exists(dataset_dir+temp2+temp):\n",
    "#             # move the image to this path\n",
    "#             print(get_image,\"Loaded to\",temp2+temp)\n",
    "#             move_image = shutil.copy(get_image,dataset_dir+temp2+temp)\n",
    "\n",
    "\n",
    "\n",
    "# # # with open(filename, 'w', newline='') as writeFile:\n",
    "# # #     writer = csv.writer(writeFile)\n",
    "# # #     writer.writerow(['filename','id']) # writing the header for the csv file (names of the columns)\n",
    "# # #     i=0\n",
    "# # #     for sub_dir in sub_dirs:\n",
    "# # #         for filename in os.listdir(sub_dir):\n",
    "# # #             print('image with id: ',filename,' loaded to ',sub_dir)\n",
    "# # #             writer.writerow([filename,class_names[i]])\n",
    "# # #         i=i+1\n",
    "\n",
    "# # # writeFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas\n",
    "# import shutil \n",
    "# import os\n",
    "\n",
    "# dataset_dir=\"D:\\\\GP\\\\New version\\\\test\\\\\" # the dir of the csv file\n",
    "\n",
    "# csv_name=\"train_test.csv\"\n",
    "\n",
    "# csv_file = pandas.read_csv(dataset_dir+csv_name) # you can implement options as you want here)\n",
    "\n",
    "# sorted_csv = csv_file.sort_values(by=['dataset'])\n",
    "# print(sorted_csv[1:10])\n",
    "# class_names = list(sorted_csv['id'].unique())\n",
    "\n",
    "# train_csv = csv_file.loc[csv_file['dataset']=='NEWEST_DATASET_BUMPS']\n",
    "\n",
    "# test_csv  =csv_file.loc[csv_file['dataset']=='train']\n",
    "# datasets_csv=[train_csv,test_csv]\n",
    "# print(train_csv[1:10],test_csv[1:10])\n",
    "# dataset_dir='D:/GP/New version/test/' # the dir for creating the folders of new datasets\n",
    "\n",
    "# if not os.path.exists(dataset_dir+'NEWEST_DATASET_BUMPS/'+'001') or not os.path.exists(dataset_dir+'NEWEST_DATASET_BUMPS/'+'002')or not os.path.exists(dataset_dir+'NEWEST_DATASET_BUMPS/'+'003'):\n",
    "#   os.makedirs(os.path.join(dataset_dir+'NEWEST_DATASET_BUMPS/'+'001'))\n",
    "#   os.makedirs(os.path.join(dataset_dir+'NEWEST_DATASET_BUMPS/'+'002'))\n",
    "#   os.makedirs(os.path.join(dataset_dir+'NEWEST_DATASET_BUMPS/'+'003'))\n",
    "  \n",
    "#   os.makedirs(os.path.join(dataset_dir+'train/'+'001'))\n",
    "#   os.makedirs(os.path.join(dataset_dir+'train/'+'002'))\n",
    "#   os.makedirs(os.path.join(dataset_dir+'train/'+'003'))\n",
    "#   print(\"created\")\n",
    "\n",
    "\n",
    "\n",
    "# dataset_names=['NEWEST_DATASET_BUMPS/','train/']\n",
    "\n",
    "# # data_locs=[\"D:/GP/New version/PotHole/001/roads/\",\"D:/GP/New version/PotHole/001/bumps/\"]\n",
    "# # print(sorted_csv.where(sorted_csv['id']==1 and sorted_csv['dataset']=='train'))\n",
    "# j=0\n",
    "# for dataset_csv in datasets_csv:\n",
    "#   for i in class_names:\n",
    "#     temp='00'+str(i)\n",
    "#     for c in list(dataset_csv[dataset_csv['id']== i]['filename']):    # c  ->  individual image \n",
    "#     # Creating path to the image\n",
    "#       # print(c)\n",
    "#       get_image = os.path.join(dataset_dir,c)\n",
    "#       # print(get_image)\n",
    "#       # get_image to that path\n",
    "      \n",
    "#       if os.path.exists(dataset_dir+dataset_names[j]+'/'+temp):\n",
    "#           # move the image to this path\n",
    "#           print(get_image,\"Loaded to\",dataset_names[j]+'/'+temp)\n",
    "#           move_image = shutil.copy(get_image,dataset_dir+dataset_names[j]+temp)\n",
    "#   j=j+1\n",
    "          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create The Final Merged Dataset Based On The Given CSV "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas\n",
    "# import shutil \n",
    "# import os\n",
    "# main_dir='D:/GP/New version/Merged_dataset/'\n",
    "# csv_file = pandas.read_csv(main_dir+\"images.csv\") # you can implement options as you want here)\n",
    "# sorted_csv = csv_file.sort_values(by=['id'])\n",
    "# class_names = list(sorted_csv['id'].unique())\n",
    "# print(class_names)\n",
    "# print()\n",
    "# if not os.path.exists(main_dir+'New folder/001') or not os.path.exists(main_dir+'New folder/002'):\n",
    "#   os.makedirs(os.path.join(main_dir+'New folder/001'))\n",
    "#   os.makedirs(os.path.join(main_dir+'New folder/002'))\n",
    "#   os.makedirs(os.path.join(main_dir+'New folder/003'))\n",
    "#   os.makedirs(os.path.join(main_dir+'New folder/004'))\n",
    "#   print(\"created\")\n",
    "\n",
    "# for i in class_names:\n",
    "#   temp='00'+str(i)          \n",
    "#   for c in list(sorted_csv[sorted_csv['id']== i]['filename']):    # c  ->  individual image \n",
    "#   # Creating path to the image\n",
    "#     get_image = os.path.join(main_dir+'New folder/',c)\n",
    "#     # print(get_image)\n",
    "#   # get_image to that path\n",
    "#     if os.path.exists(main_dir+'New folder/'+temp):\n",
    "#         # move the image to this path\n",
    "#         print(get_image,\"Loaded to\",temp)\n",
    "#         move_image = shutil.copy(get_image,main_dir+'New folder/'+temp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # print(sorted_csv)\n",
    "# road_images_count=len(sorted_csv[sorted_csv['Label']== 0])\n",
    "# pothole_images_count=len(sorted_csv[sorted_csv['Label']== 1])\n",
    "# print(\"road_images_count: \"+str(road_images_count),\"\\npothole_images_count: \"+str(pothole_images_count))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Essential Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "import PIL.Image\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "NUM_CLASSES = 3 #Bump/Road/pothole\n",
    "IMG_SIZE =224 #SqueezeNet 90x90\n",
    "SHOULD_TEST = False\n",
    "\n",
    "EPOCHS = 40\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device_name = tf.test.gpu_device_name()\n",
    "if not device_name:\n",
    "  raise SystemError('GPU device not found')\n",
    "print('Found GPU at: {}'.format(device_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ju2yXtdV5YaT"
   },
   "source": [
    "Note: all images are licensed CC-BY, creators are listed in the LICENSE.txt file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "\n",
    "data_dirs_string=['D:/GP/New version/NEWEST_DATASET_BUMPS','D:/GP/New version/train','D:/GP/New version/PotHole']\n",
    "data_dirs=[]\n",
    "for i in data_dirs_string:\n",
    "  data_dirs.append(pathlib.Path(i))\n",
    "\n",
    "# data_dir = 'D:/GP/New version/NEWEST_DATASET_BUMPS'\n",
    "# data_dir = pathlib.Path(data_dir)\n",
    "\n",
    "# data_dir2 = 'D:/GP/New version/train'\n",
    "# data_dir2 = pathlib.Path(data_dir2)\n",
    "\n",
    "# # data_dir3 = 'D:/GP/New version/train'\n",
    "# # data_dir3 = pathlib.Path(data_dir2)\n",
    "\n",
    "# data_dir3 = 'D:/GP/New version/PotHole'\n",
    "# data_dir3 = pathlib.Path(data_dir3)\n",
    "# image_count_train = len(list(data_dirs[0].glob('*/*.*')))+len(list(data_dirs[1].glob('*/*.*')))+len(list(data_dirs[2].glob('*/*.*'))) \n",
    "# print(image_count_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names=[]\n",
    "for i in range(NUM_CLASSES):\n",
    "  Class = np.array(sorted([item.name for item in data_dirs[i].glob('*') if item.name != \"LICENSE.txt\"]))\n",
    "  for i in Class:\n",
    "    if i not in class_names:\n",
    "      class_names.append(i)\n",
    "print(class_names)\n",
    "# class_names = np.array(sorted([item.name for item in data_dir2.glob('*') if item.name != \"LICENSE.txt\"]))\n",
    "# print(class_names)\n",
    "# class_names = np.array(sorted([item.name for item in data_dir3.glob('*') if item.name != \"LICENSE.txt\"]))\n",
    "# print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-26T06:29:44.484086Z",
     "iopub.status.busy": "2022-01-26T06:29:44.483305Z",
     "iopub.status.idle": "2022-01-26T06:29:44.497795Z",
     "shell.execute_reply": "2022-01-26T06:29:44.498148Z"
    },
    "id": "lAkQp5uxoINu"
   },
   "outputs": [],
   "source": [
    "\n",
    "dataSets=[tf.data.Dataset for x in range(NUM_CLASSES)]\n",
    "dir=[]\n",
    "image_count_train=np.zeros(NUM_CLASSES)\n",
    "\n",
    "for j in range(NUM_CLASSES):\n",
    "  for i in range(NUM_CLASSES):\n",
    "  # if not os.path.exists(str(data_dirs[i]/+class_names[j]+'/*')): \n",
    "    temp=str(class_names[j]+'/*')\n",
    "    dir.append(str(data_dirs[i]/temp))\n",
    "  # print(dir)  \n",
    "  dataSets[j]=(tf.data.Dataset.list_files(dir, shuffle=False))\n",
    "  dir=[]\n",
    "  image_count_train[j]=int(len(dataSets[j]))\n",
    "  dataSets[j] = dataSets[j].shuffle(image_count_train[j], reshuffle_each_iteration=False)\n",
    "  \n",
    "print(\"Length of each dataset: \",image_count_train)\n",
    "\n",
    "minIndex=np.argmin(image_count_train)\n",
    "# print(\"Min. Length is: \",minLen)    \n",
    "\n",
    "list_ds_train=dataSets[minIndex]\n",
    "for i in range(NUM_CLASSES):\n",
    "  if i != minIndex:\n",
    "    # print(\"hi\")\n",
    "    list_ds_train = list_ds_train.concatenate(dataSets[i]) #.take(minLen))\n",
    "minLen= len(list(list_ds_train.as_numpy_iterator()))\n",
    "list_ds_train = list_ds_train.shuffle(NUM_CLASSES*minLen, reshuffle_each_iteration=False)\n",
    "\n",
    "print('train size:' , len(list(list_ds_train.as_numpy_iterator())))\n",
    "# list_ds_train = list_ds_train.batch(BATCH_SIZE).prefetch(2)\n",
    "\n",
    "# list_ds_test = tf.data.Dataset.list_files([str(data_dir2/'*/*')], shuffle=False)\n",
    "# list_ds_test = list_ds_test.shuffle(image_count_test, reshuffle_each_iteration=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-26T06:29:44.503154Z",
     "iopub.status.busy": "2022-01-26T06:29:44.502237Z",
     "iopub.status.idle": "2022-01-26T06:29:44.512927Z",
     "shell.execute_reply": "2022-01-26T06:29:44.513285Z"
    },
    "id": "coORvEH-NGwc"
   },
   "outputs": [],
   "source": [
    "for f in list_ds_train.take(5):\n",
    "  print(f.numpy())\n",
    "\n",
    "# for f in list_ds_test.take(5):\n",
    "#   print(f.numpy())  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6NLQ_VJhWO4z"
   },
   "source": [
    "The tree structure of the files can be used to compile a `class_names` list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CiptrWmAlmAa"
   },
   "source": [
    "Split the dataset into training and validation sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-26T06:29:44.524897Z",
     "iopub.status.busy": "2022-01-26T06:29:44.524044Z",
     "iopub.status.idle": "2022-01-26T06:29:44.548354Z",
     "shell.execute_reply": "2022-01-26T06:29:44.547835Z"
    },
    "id": "GWHNPzXclpVr"
   },
   "outputs": [],
   "source": [
    "# image_count=sum(image_count_train)\n",
    "# print(image_count*0.2)\n",
    "test_size = int(minLen *0.2)\n",
    "val_size = int(minLen * 0.2)\n",
    "test_ds = list_ds_train.take(test_size)\n",
    "val_ds = list_ds_train.skip(test_size).take(val_size)\n",
    "train_ds = list_ds_train.skip(val_size+test_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rkB-IR4-pS3U"
   },
   "source": [
    "You can print the length of each dataset as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-26T06:29:44.552974Z",
     "iopub.status.busy": "2022-01-26T06:29:44.552265Z",
     "iopub.status.idle": "2022-01-26T06:29:44.554832Z",
     "shell.execute_reply": "2022-01-26T06:29:44.555181Z"
    },
    "id": "SiKQrb9ppS-7"
   },
   "outputs": [],
   "source": [
    "print('test size:' , len(list(test_ds.as_numpy_iterator())))\n",
    "print('train size:' , len(list(train_ds.as_numpy_iterator())))\n",
    "print('dev size:' , len(list(val_ds.as_numpy_iterator())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "91CPfUUJ_8SZ"
   },
   "source": [
    "Write a short function that converts a file path to an `(img, label)` pair:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-26T06:29:44.559661Z",
     "iopub.status.busy": "2022-01-26T06:29:44.558876Z",
     "iopub.status.idle": "2022-01-26T06:29:44.560674Z",
     "shell.execute_reply": "2022-01-26T06:29:44.561025Z"
    },
    "id": "arSQzIey-4D4"
   },
   "outputs": [],
   "source": [
    "def get_label(file_path):\n",
    "  # Convert the path to a list of path components\n",
    "  parts = tf.strings.split(file_path, os.path.sep)\n",
    "  # The second to last is the class-directory\n",
    "  \n",
    "  one_hot = parts[-2] == class_names\n",
    "  # Integer encode the label\n",
    "  return tf.argmax(one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-26T06:29:44.565350Z",
     "iopub.status.busy": "2022-01-26T06:29:44.564567Z",
     "iopub.status.idle": "2022-01-26T06:29:44.566772Z",
     "shell.execute_reply": "2022-01-26T06:29:44.566353Z"
    },
    "id": "MGlq4IP4Aktb"
   },
   "outputs": [],
   "source": [
    "def decode_img(img):\n",
    "  # Convert the compressed string to a 3D uint8 tensor\n",
    "  img = tf.io.decode_jpeg(img, channels=3)\n",
    "  # Resize the image to the desired size\n",
    "  return tf.image.resize(img, [IMG_SIZE, IMG_SIZE])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-26T06:29:44.570920Z",
     "iopub.status.busy": "2022-01-26T06:29:44.570131Z",
     "iopub.status.idle": "2022-01-26T06:29:44.572396Z",
     "shell.execute_reply": "2022-01-26T06:29:44.571964Z"
    },
    "id": "-xhBRgvNqRRe"
   },
   "outputs": [],
   "source": [
    "def process_path(file_path):\n",
    "  label = get_label(file_path)\n",
    "  # Load the raw data from the file as a string\n",
    "  img = tf.io.read_file(file_path)\n",
    "  img = decode_img(img)\n",
    "  return img, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S9a5GpsUOBx8"
   },
   "source": [
    "Use `Dataset.map` to create a dataset of `image, label` pairs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-26T06:29:44.577584Z",
     "iopub.status.busy": "2022-01-26T06:29:44.576790Z",
     "iopub.status.idle": "2022-01-26T06:29:44.737954Z",
     "shell.execute_reply": "2022-01-26T06:29:44.738344Z"
    },
    "id": "3SDhbo8lOBQv"
   },
   "outputs": [],
   "source": [
    "# Set `num_parallel_calls` so multiple images are loaded/processed in parallel.\n",
    "train_ds = train_ds.map(process_path, num_parallel_calls=AUTOTUNE)\n",
    "val_ds = val_ds.map(process_path, num_parallel_calls=AUTOTUNE)\n",
    "test_ds = test_ds.map(process_path, num_parallel_calls=AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-26T06:29:44.743331Z",
     "iopub.status.busy": "2022-01-26T06:29:44.742385Z",
     "iopub.status.idle": "2022-01-26T06:29:44.784823Z",
     "shell.execute_reply": "2022-01-26T06:29:44.785182Z"
    },
    "id": "kxrl0lGdnpRz"
   },
   "outputs": [],
   "source": [
    "# c=0\n",
    "# c1=0\n",
    "# c2=0\n",
    "# for image, label in train_ds:\n",
    "#   # print(\"Image shape: \", image.numpy().shape)\n",
    "#   # print(\"Label: \", label.numpy())\n",
    "#   if(label.numpy()==0):\n",
    "#     c=c+1\n",
    "#   elif (label.numpy()==1):\n",
    "#     c1=c1+1\n",
    "#   elif(label.numpy()==2):\n",
    "#     c2=c2+1\n",
    "#   # print(label.numpy())\n",
    "# print(c,c1,c2)\n",
    "# c=c1=c2=0\n",
    "# for image, label in test_ds:\n",
    "#   # print(\"Image shape: \", image.numpy().shape)\n",
    "#   # print(\"Label: \", label.numpy())\n",
    "\n",
    "#   if(label.numpy()==0):\n",
    "#     c=c+1\n",
    "#   elif (label.numpy()==1):\n",
    "#     c1=c1+1\n",
    "#   elif(label.numpy()==2):\n",
    "#     c2=c2+1\n",
    "#   # print(label.numpy())\n",
    "# print(c,c1,c2)\n",
    "# c=c1=c2=0\n",
    "# for image, label in val_ds:\n",
    "#   # print(\"Image shape: \", image.numpy().shape)\n",
    "#   # print(\"Label: \", label.numpy())\n",
    "\n",
    "#   if(label.numpy()==0):\n",
    "#     c=c+1\n",
    "#   elif (label.numpy()==1):\n",
    "#     c1=c1+1\n",
    "#   elif(label.numpy()==2):\n",
    "#     c2=c2+1\n",
    "#   # print(label.numpy())\n",
    "# print(c,c1,c2)\n",
    "\n",
    "\n",
    "#   # images.append(image)\n",
    "#   # labels.append(label.numpy())\n",
    "#   # 193 201 179\n",
    "\n",
    "#   # 178 218 177"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vYGCgJuR_9Qp"
   },
   "source": [
    "### Configure dataset for performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wwZavzgsIytz"
   },
   "source": [
    "To train a model with this dataset you will want the data:\n",
    "\n",
    "* To be well shuffled.\n",
    "* To be batched.\n",
    "* Batches to be available as soon as possible.\n",
    "\n",
    "These features can be added using the `tf.data` API. For more details, visit the [Input Pipeline Performance](../../guide/performance/datasets.ipynb) guide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-26T06:29:44.790092Z",
     "iopub.status.busy": "2022-01-26T06:29:44.789534Z",
     "iopub.status.idle": "2022-01-26T06:29:44.794535Z",
     "shell.execute_reply": "2022-01-26T06:29:44.794888Z"
    },
    "id": "uZmZJx8ePw_5"
   },
   "outputs": [],
   "source": [
    "def configure_for_performance(ds):\n",
    "  ds = ds.cache()\n",
    "  ds = ds.shuffle(buffer_size=1000)\n",
    "  ds = ds.batch(BATCH_SIZE)\n",
    "  ds = ds.prefetch(buffer_size=AUTOTUNE)\n",
    "  return ds\n",
    "\n",
    "train_ds = configure_for_performance(train_ds)\n",
    "val_ds = configure_for_performance(val_ds)\n",
    "test_ds = configure_for_performance(test_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "45P7OvzRWzOB"
   },
   "source": [
    "### Visualize the data\n",
    "\n",
    "You can visualize this dataset similarly to the one you created previously:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-26T06:29:44.799476Z",
     "iopub.status.busy": "2022-01-26T06:29:44.798931Z",
     "iopub.status.idle": "2022-01-26T06:29:45.664291Z",
     "shell.execute_reply": "2022-01-26T06:29:45.664666Z"
    },
    "id": "UN_Dnl72YNIj"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "image_batch, label_batch = next(iter(train_ds))\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i in range(9):\n",
    "  ax = plt.subplot(3, 3, i + 1)\n",
    "  plt.imshow(image_batch[i].numpy().astype(\"uint8\"))\n",
    "  label = label_batch[i]\n",
    "  plt.title(class_names[label])\n",
    "  plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XqHjIr6cplwY"
   },
   "source": [
    "### Train a model\n",
    "\n",
    "For completeness, you will show how to train a simple model using the datasets you have just prepared.\n",
    "\n",
    "The [Sequential](https://www.tensorflow.org/guide/tf/sequential_model) model consists of three convolution blocks (`tf.tf.layers.Conv2D`) with a max pooling layer (`tf.tf.layers.MaxPooling2D`) in each of them. There's a fully-connected layer (`tf.tf.layers.Dense`) with 128 units on top of it that is activated by a ReLU activation function (`'relu'`). This model has not been tuned in any wayâ€”the goal is to show you the mechanics using the datasets you just created. To learn more about image classification, visit the [Image classification](../images/classification.ipynb) tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from sklearn.metrics import accuracy_score,f1_score,precision_score,recall_score\n",
    "\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.losses import categorical_crossentropy\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, BatchNormalization, Concatenate, Dropout, Activation, Input, ZeroPadding2D, LayerNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "#from tensorflow.keras.metrics import Accuracy, Recall, Precision\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "    # y_true = keras.backend.ones_like(y_true) \n",
    "    # true_positives = keras.backend.sum(keras.backend.round(keras.backend.clip(y_true * y_pred, 0, 1)))\n",
    "    # all_positives = keras.backend.sum(keras.backend.round(keras.backend.clip(y_true, 0, 1)))\n",
    "    # print(y_pred)\n",
    "    # print(y_true)\n",
    "    # recall = true_positives / (all_positives + keras.backend.epsilon())\n",
    "    y_pred=y_pred.numpy()\n",
    "    y_true=y_true.numpy()\n",
    "    y_pred=np.argmax(y_pred, axis=-1)\n",
    "    return recall_score(y_true, y_pred,labels=[0,1,2], average='weighted')\n",
    "\n",
    "\n",
    "def precision(y_true, y_pred):\n",
    "    # y_true = keras.backend.ones_like(y_true) \n",
    "    # true_positives = keras.backend.sum(keras.backend.round(keras.backend.clip(y_true * y_pred, 0, 1)))\n",
    "    # print(true_positives)\n",
    "\n",
    "    # predicted_positives = keras.backend.sum(keras.backend.round(keras.backend.clip(y_pred, 0, 1)))\n",
    "    # precision = true_positives / (predicted_positives + keras.backend.epsilon())\n",
    "    y_pred=y_pred.numpy()\n",
    "    y_true=y_true.numpy()\n",
    "    y_pred=np.argmax(y_pred, axis=-1)\n",
    "    return precision_score(y_true, y_pred,labels=[0,1,2], average='weighted')\n",
    "\n",
    "def F1_score(y_true, y_pred):\n",
    "    # prec = precision(y_true, y_pred)\n",
    "    # rec = recall(y_true, y_pred)\n",
    "    y_pred=y_pred.numpy()\n",
    "    y_true=y_true.numpy()\n",
    "    y_pred=np.argmax(y_pred, axis=-1)\n",
    "    return f1_score(y_true, y_pred,labels=[0,1,2], average='weighted', )\n",
    "\n",
    "\n",
    "class FireModule(keras.layers.Layer):\n",
    "    def __init__(self, s1x1, e1x1, e3x3):\n",
    "        super(FireModule, self).__init__()\n",
    "        16,64,64\n",
    "        self.s1x1 = Conv2D(s1x1, kernel_size=(1, 1), padding='same', kernel_initializer='glorot_normal', activation='relu')\n",
    "        self.e1x1 = Conv2D(e1x1, kernel_size=(1, 1), padding='same', kernel_initializer='glorot_normal', activation='relu')\n",
    "        self.e3x3 = Conv2D(e3x3, kernel_size=(3, 3), padding='same', kernel_initializer='glorot_normal', activation='relu')\n",
    "        self.concat = Concatenate(axis=3)\n",
    "    \n",
    "    def get_config(self):\n",
    "        base_config = super(FireModule, self).get_config()\n",
    "        #base_config['output_dim'] = self.output_dim\n",
    "        return base_config\n",
    "\n",
    "    def call(self, inputs):\n",
    "        s1x1 = self.s1x1(inputs)\n",
    "        e1x1 = self.e1x1(s1x1)\n",
    "        e3x3 = self.e3x3(s1x1)\n",
    "        concat = self.concat([e1x1, e3x3])\n",
    "        return concat\n",
    "\n",
    "# def FireModule(s1, e1, e3, input):\n",
    "#     squeeze = Conv2D(s1, kernel_size=(1, 1), padding='same', kernel_initializer='glorot_normal', activation='relu')(input)\n",
    "#     expand1 = Conv2D(e1, kernel_size=(1, 1), padding='same', kernel_initializer='glorot_normal', activation='relu')(squeeze)\n",
    "#     expand3 = Conv2D(e3, kernel_size=(3, 3), padding='same', kernel_initializer='glorot_normal', activation='relu')(squeeze)\n",
    "#     concat = Concatenate(axis=1)([expand1, expand3])\n",
    "#     return concat\n",
    "\n",
    "def SqueezeNetV1_0(input_shape, nb_classes):\n",
    "    input = Input(input_shape)\n",
    "    padded = ZeroPadding2D((2, 2))(input)\n",
    "    conv1 = Conv2D(96, kernel_size=(7, 7), strides=(2,2),padding='valid', kernel_initializer='glorot_normal', activation='relu')(padded)\n",
    "    maxpool1 = MaxPooling2D(pool_size=(3, 3), strides=2)(conv1)\n",
    "    fire2 = FireModule(16, 64, 64)(maxpool1)\n",
    "    fire3 = FireModule(16, 64, 64)(fire2)\n",
    "    fire4 = FireModule(32, 128, 128)(fire3)\n",
    "    maxpool4 = MaxPooling2D(pool_size=(3, 3), strides=2)(fire4)\n",
    "    fire5 = FireModule(32, 128, 128)(maxpool4)\n",
    "    fire6 = FireModule(48, 192, 192)(fire5)\n",
    "    fire7 = FireModule(48, 192, 192)(fire6)\n",
    "    fire8 = FireModule(64, 256, 256)(fire7)\n",
    "    maxpool8 = MaxPooling2D(pool_size=(3, 3), strides=2)(fire8)\n",
    "    fire9 = FireModule(64, 256, 256)(maxpool8)\n",
    "    conv10 = Conv2D(1000, kernel_size=(1, 1), strides=1, padding='same', kernel_initializer='glorot_normal', activation='relu')(fire9)\n",
    "    avgpool10 = AveragePooling2D(conv10.get_shape()[1:3], strides=1)(conv10)\n",
    "    #reshaped = tf.squeeze(avgpool10, [1, 2])\n",
    "    flat = Flatten()(avgpool10)\n",
    "    # output = Activation('softmax')(flat)\n",
    "    output = Dense(nb_classes, activation='softmax', kernel_initializer='he_normal')(flat)\n",
    "\n",
    "\n",
    "    model = Model(input, output, name='SqueezeNetV1_0x' + str(IMG_SIZE))\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "                loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def SqueezeNetV1_1(input_shape, nb_classes):\n",
    "    input = Input(input_shape)\n",
    "    conv1 = Conv2D(64, kernel_size=(3, 3), strides=(2,2),padding='valid')(input)\n",
    "    maxpool1 = MaxPooling2D(pool_size=(3, 3), strides=2)(conv1)\n",
    "    fire2 = FireModule(16, 64, 64)(maxpool1)\n",
    "    fire3 = FireModule(16, 64, 64)(fire2)\n",
    "    maxpool3 = MaxPooling2D(pool_size=(3, 3), strides=2)(fire3)\n",
    "    fire4 = FireModule(32, 128, 128)(maxpool3)\n",
    "    fire5 = FireModule(32, 128, 128)(fire4)\n",
    "    maxpool5 = MaxPooling2D(pool_size=(3, 3), strides=2)(fire5)\n",
    "    fire6 = FireModule(48, 192, 192)(maxpool5)\n",
    "    fire7 = FireModule(48, 192, 192)(fire6)\n",
    "    fire8 = FireModule(64, 256, 256)(fire7)\n",
    "    fire9 = FireModule(64, 256, 256)(fire8)\n",
    "    dropout9 = Dropout(0.8)(fire9)\n",
    "    conv10 = Conv2D(nb_classes, kernel_size=(1, 1), strides=1, padding='same', activation=None)(dropout9)\n",
    "    avgpool10 = AveragePooling2D(conv10.get_shape()[1:3])(conv10)\n",
    "    #reshaped10 = Flatten()(avgpool10)\n",
    "    output = Flatten()(avgpool10)\n",
    "    #output = Activation('softmax')(reshaped10)\n",
    "    #output = Dense(nb_classes, activation='softmax', kernel_initializer='he_normal')(reshaped10)\n",
    "\n",
    "    model = Model(input, output, name='SqueezeNetV1_1x' + str(IMG_SIZE))\n",
    "    model.compile(optimizer='adam',\n",
    "                loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                metrics=['accuracy', precision, recall, F1_score])\n",
    "    return model\n",
    "\n",
    "\n",
    "def FLSCNN(input_shape, nb_classes):\n",
    "    input = Input(input_shape)\n",
    "\n",
    "    conv1 = Conv2D(8, kernel_size=(5, 5),activation='relu')(input)\n",
    "    bn1 = LayerNormalization()(conv1)\n",
    "    \n",
    "    maxpool1 = MaxPooling2D(pool_size=(4, 4), strides=2, padding='same')(bn1)\n",
    "    \n",
    "    conv2 = Conv2D(16, kernel_size=(5, 5), activation='relu')(maxpool1)\n",
    "    bn2 = LayerNormalization()(conv2)\n",
    "\n",
    "    maxpool2 = MaxPooling2D(pool_size=(4, 4), strides=2, padding='same')(bn2)\n",
    "    \n",
    "    conv3 = Conv2D(16, kernel_size=(5, 5), activation='relu')(maxpool2)\n",
    "    bn3 = LayerNormalization()(conv3)\n",
    "\n",
    "    maxpool3 = MaxPooling2D(pool_size=(3, 3), strides=2)(bn3)\n",
    "\n",
    "    conv4 = Conv2D(32, kernel_size=(5, 5), activation='relu')(maxpool3)\n",
    "    bn4 = LayerNormalization()(conv4)\n",
    "\n",
    "    maxpool4 = MaxPooling2D(pool_size=(5, 5), strides=2, padding='same')(bn4)\n",
    "\n",
    "    conv5 = Conv2D(32, kernel_size=(1, 1), activation='relu', padding='same')(maxpool4)\n",
    "    bn5 = LayerNormalization()(conv5)\n",
    "\n",
    "    maxpool5 = MaxPooling2D(pool_size=(3, 3), strides=2, padding='valid')(bn5)\n",
    "\n",
    "    #maxpool6 = MaxPooling2D(pool_size=(3, 3), strides=1, padding='valid')(maxpool5)\n",
    "\n",
    "    fc1 = Dense(32, activation='tanh',)(maxpool5)\n",
    "    fc2 = Dense(4, activation='tanh',)(fc1)\n",
    "    fc3 = Dense(nb_classes, activation='softmax',)(fc2)\n",
    "\n",
    "    output = Flatten()(fc3)\n",
    "\n",
    "    model = Model(input, output, name='FLSCNNx' + str(IMG_SIZE))\n",
    "    model.compile(optimizer=Adam(learning_rate=0.09),\n",
    "                loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d83f5aa7f3fb"
   },
   "source": [
    "Choose the `tf.keras.optimizers.Adam` optimizer and `tf.keras.losses.SparseCategoricalCrossentropy` loss function. To view training and validation accuracy for each training epoch, pass the `metrics` argument to `Model.compile`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for images, labels in train_ds.take(1):\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-26T06:29:38.121144Z",
     "iopub.status.busy": "2022-01-26T06:29:38.120510Z",
     "iopub.status.idle": "2022-01-26T06:29:38.126328Z",
     "shell.execute_reply": "2022-01-26T06:29:38.126669Z"
    },
    "id": "t_BlmsnmsEr4"
   },
   "outputs": [],
   "source": [
    "model = SqueezeNetV1_1((224,224,3), NUM_CLASSES)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ffwd44ldNMOE"
   },
   "source": [
    "Note: You will only train for a few epochs so this tutorial runs quickly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "# Place the logs in a timestamped subdirectory\n",
    "# This allows to easy select different training runs\n",
    "# In order not to overwrite some data, it is useful to have a name with a timestamp\n",
    "log_dir=\"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "# Specify the callback object\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1, profile_batch = (50,80))\n",
    "\n",
    "# tf.keras.callback.TensorBoard ensures that logs are created and stored\n",
    "# We need to pass callback object to the fit method\n",
    "# The way to do this is by passing the list of callback objects, which is in our case just one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"training_1/cp.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "# Create a callback that saves the model's weights\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.run_functions_eagerly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-26T06:29:38.130807Z",
     "iopub.status.busy": "2022-01-26T06:29:38.130262Z",
     "iopub.status.idle": "2022-01-26T06:29:44.478265Z",
     "shell.execute_reply": "2022-01-26T06:29:44.478658Z"
    },
    "id": "S08ZKKODsnGW"
   },
   "outputs": [],
   "source": [
    "from shutil import rmtree\n",
    "\n",
    "rmtree('./logs')\n",
    "model.fit(\n",
    "  train_ds,\n",
    "  epochs=EPOCHS,\n",
    "  validation_data=val_ds,\n",
    "  callbacks=[tensorboard_callback, cp_callback]\n",
    ")\n",
    "model.save('models/'+model.name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model = load_model('models/'+model.name, custom_objects={'recall': recall, 'precision': precision,'f1_score':F1_score})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_accuracy = tf.keras.metrics.Accuracy()\n",
    "# test_precision = tf.keras.metrics.Precision()\n",
    "# test_recall= tf.keras.metrics.Recall()\n",
    "# #ds_test_batch = test_ds.batch(10)\n",
    "\n",
    "loss, accuracy, prec, rec, f1 = model.evaluate(test_ds)\n",
    "print(\"Loss :\", loss)\n",
    "print(\"Accuracy :\", accuracy)\n",
    "print(\"Precision :\", prec)\n",
    "print(\"Recall :\", rec)\n",
    "print(\"F1-Score :\", f1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_ds.take(1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing With A Video Stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from uuid import uuid4\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "count=0\n",
    "Slow = cv2.imread(\"SlowDown.png\")\n",
    "size = 100\n",
    "Slow = cv2.resize(Slow, (size, size))\n",
    "img2gray = cv2.cvtColor(Slow, cv2.COLOR_BGR2GRAY)\n",
    "ret, mask = cv2.threshold(img2gray, 1, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "videos_dir=['Road.avi','Bumps.avi','Potholes.mp4']\n",
    "accs=np.zeros(len(videos_dir))\n",
    "for i in range(len(videos_dir)):\n",
    "    cap = cv2.VideoCapture(videos_dir[i])\n",
    "    images = []\n",
    "    bumps=0\n",
    "    pothole=0\n",
    "    frames=0\n",
    "    print(\"count:\",count)\n",
    "    while(cap.isOpened()):\n",
    "        ret, frame = cap.read()\n",
    "        if ret == True:\n",
    "            # print(frame.shape)\n",
    "            # cv2.imwrite(\"q/frame%d.jpg\" % count, frame) \n",
    "\n",
    "            frames=frames+1\n",
    "            image = tf.image.resize(frame, [IMG_SIZE, IMG_SIZE])\n",
    "            image=tf.convert_to_tensor(frame)\n",
    "            image= tf.image.resize(image, [IMG_SIZE, IMG_SIZE])\n",
    "            image= tf.expand_dims(image,0)\n",
    "\n",
    "            roi = frame[-size-10:-10, -size-10:-10]\n",
    "            # Set an index of where the mask is\n",
    "            roi[np.where(mask)] = 0\n",
    "            \n",
    "\n",
    "            label = np.argmax(model.predict(image))\n",
    "            if  i==2 and label !=2:\n",
    "                label=label+1 \n",
    "            cv2.imshow('Frame',frame)\n",
    "            if label==0:\n",
    "                print(\"The Prediction is: Road\")\n",
    "            elif label==1:\n",
    "                print(\"The Prediction is: Bump\")\n",
    "            else:\n",
    "                print(\"The Prediction is: Pothole\")\n",
    "            \n",
    "            print(label)\n",
    "            if label == 1:\n",
    "                bumps=bumps+1\n",
    "                # c=input()\n",
    "                frame = cv2.circle(frame, (160,20), radius=0, color=(0, 0, 255), thickness=30)#for bumb\n",
    "                roi += Slow \n",
    "            elif label == 2:\n",
    "                pothole=pothole+1\n",
    "                # c=input()\n",
    "                frame = cv2.circle(frame, (180,70), radius=0, color=(255, 0, 0), thickness=30) #for pothole\n",
    "                roi += Slow \n",
    "            cv2.putText(img=frame, text='Bump', org=(0, 30), fontFace=cv2.FONT_HERSHEY_TRIPLEX, fontScale=1.0, color=(0, 0, 255),thickness=0) \n",
    "            cv2.putText(img=frame, text='Pothole', org=(0, 80), fontFace=cv2.FONT_HERSHEY_TRIPLEX, fontScale=1.0, color=(255, 0, 0),thickness=0)\n",
    "            cv2.imshow('Frame',frame)\n",
    "            # Press Q on keyboard to  exit\n",
    "            # c=input()\n",
    "            count=count+1\n",
    "            \n",
    "            if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "                break\n",
    "        else:\n",
    "            break\n",
    "    if i==0:\n",
    "        print(\"number of 1st vides frames are\",frames)\n",
    "        accs[i]=1-((bumps+pothole)/frames)\n",
    "    elif i==1:\n",
    "        print(\"number of 2nd vides frames are\",frames)\n",
    "        accs[i]=bumps/frames\n",
    "    else:\n",
    "        print(\"number of 3rd vides frames are\",frames)\n",
    "        accs[i]=pothole/frames\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# print(\"total accuracy\",(pothole)/frames)\n",
    "print(\"Accuracy Of Road\",accs[0])\n",
    "print(\"Accuracy Of Bumps\",accs[1])\n",
    "print(\"Accuracy Of Potholes\",accs[2])\n",
    "print(\"AVG Accuracy\",accs.sum()/len(videos_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Video Stream Using Seprated Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "img_array = []\n",
    "for filename in glob.glob('q\\\\1\\\\*.*'):\n",
    "    img = cv2.imread(filename)\n",
    "    height, width, layers = img.shape\n",
    "    size = (width,height)\n",
    "    img_array.append(img)\n",
    "    print(filename,'is loaded to the video')\n",
    "print(len(img_array))\n",
    "\n",
    "\n",
    "#convert img_array to video\n",
    "# out = cv2.VideoWriter('q/output.avi',cv2.VideoWriter_fourcc(*'DIVX'), 25, size)\n",
    "# write a video of the images\n",
    "\n",
    "\n",
    "out = cv2.VideoWriter('Road_test.mp4',cv2.VideoWriter_fourcc(*'DIVX'), 10,size)\n",
    " \n",
    "for i in range(len(img_array)):\n",
    "    out.write(img_array[i])\n",
    "out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# c=c1=c2=0\n",
    "\n",
    "# for i in test:\n",
    "#   # label =np.argmax(model.predict(i))\n",
    "#   # cv2.imshow('Frame',i)\n",
    "#   # plt.imshow(image_batch[i].numpy().astype(\"uint8\"))\n",
    "#   # print('class name: '+ str())\n",
    "#   if(label==0):\n",
    "#     c=c+1\n",
    "#   elif (label==1):\n",
    "#     c1=c1+1\n",
    "#   elif(label==2):\n",
    "#     c2=c2+1\n",
    "# print(c,c1,c2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()\n",
    "model.layers[3].get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = model.layers[1].get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights[:,:,2,60]"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "images.ipynb",
   "toc_visible": true
  },
  "interpreter": {
   "hash": "c0e9f387c259db4d480008706f04ece23be5a5fe33bd4a4b28ce42f14d82d228"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('tf-gpu')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

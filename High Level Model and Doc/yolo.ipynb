{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import argparse\n",
    "import cv2\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = open('model/coco.names').read().strip().split('\\n')\n",
    "net = cv2.dnn.readNetFromDarknet('model/yolov3.cfg', 'model/yolov3.weights')\n",
    "# Create a list of colors for the labels\n",
    "colors = np.random.randint(0, 255, size=(len(labels), 3), dtype='uint8')\n",
    "\n",
    "net.setPreferableBackend(cv2.dnn.DNN_BACKEND_CUDA)\n",
    "net.setPreferableTarget(cv2.dnn.DNN_TARGET_CUDA)\n",
    "\n",
    "layer_names = net.getLayerNames()\n",
    "layer_names = [layer_names[i - 1] for i in net.getUnconnectedOutLayers()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_boxes_confidences_classids(outputs, confidence, width, height):\n",
    "    boxes = []\n",
    "    confidences = []\n",
    "    classIDs = []\n",
    "\n",
    "    for output in outputs:\n",
    "        for detection in output:            \n",
    "            # Extract the scores, classid, and the confidence of the prediction\n",
    "            scores = detection[5:]\n",
    "            classID = np.argmax(scores)\n",
    "            conf = scores[classID]\n",
    "            \n",
    "            # Consider only the predictions that are above the confidence threshold\n",
    "            if conf > confidence:\n",
    "                # Scale the bounding box back to the size of the image\n",
    "                box = detection[0:4] * np.array([width, height, width, height])\n",
    "                centerX, centerY, w, h = box.astype('int')\n",
    "\n",
    "                # Use the center coordinates, width and height to get the coordinates of the top left corner\n",
    "                x = int(centerX - (w / 2))\n",
    "                y = int(centerY - (h / 2))\n",
    "\n",
    "                boxes.append([x, y, int(w), int(h)])\n",
    "                confidences.append(float(conf))\n",
    "                classIDs.append(classID)\n",
    "\n",
    "    return boxes, confidences, classIDs\n",
    "\n",
    "\n",
    "def draw_bounding_boxes(image, boxes, confidences, classIDs, idxs, colors,SLow):\n",
    "    if len(idxs) > 0:\n",
    "        \n",
    "        \n",
    "        for i in idxs.flatten():\n",
    "            # extract bounding box coordinates\n",
    "            x, y = boxes[i][0], boxes[i][1]\n",
    "            w, h = boxes[i][2], boxes[i][3]\n",
    "            X = isInside(300, 200, 0, 512, 512, 512, x, y) or isInside(300, 200, 0, 512, 512, 512, x + w, y + h) or isInside(300, 200, 0, 512, 512, 512, x+w, y) or isInside(300, 200, 0, 512, 512, 512, x, y + h)\n",
    "            X_2 = isInside(75, 380, 260, 200, 450, 380, x, y) or isInside(75, 380, 260, 200, 450, 380, x + w, y + h) or isInside(75, 380, 260, 200, 450, 380, x+w, y) or isInside(75, 380, 260, 200, 450, 380, x, y + h)\n",
    "            p1 = (75, 380)\n",
    "            p2 = (260, 200)\n",
    "            p3 = (450, 380)\n",
    "            cv2.line(image, p1, p2, (255, 0, 0), 3)\n",
    "            cv2.line(image, p2, p3, (255, 0, 0), 3)\n",
    "            cv2.line(image, p1, p3, (255, 0, 0), 3)\n",
    "\n",
    "            # p1 = (300, 200)\n",
    "            # p2 = (0, 512)\n",
    "            # p3 = (512, 512)\n",
    "            # cv2.line(image, p1, p2, (255, 0, 0), 3)\n",
    "            # cv2.line(image, p2, p3, (255, 0, 0), 3)\n",
    "            # cv2.line(image, p1, p3, (255, 0, 0), 3)\n",
    "            area = w*h\n",
    "            # draw the bounding box and label on the image\n",
    "            # cv2.rectangle(image, (75, 300), (450, 380), (0,0,255), 2)\n",
    "            # Y = (x>75 and x<450) and (y>300 and y<380)\n",
    "            # Y_1 = (x+w>75 and x+w<450) and (y>300 and y<380)\n",
    "            # Y_2 = (x>75 and x<450) and (y+h>300 and y+h<380)\n",
    "            # Y_3 = (x+w>75 and x+w<450) and (y+h>300 and y+h<380)\n",
    "            if(classIDs[i]==0):\n",
    "                # color = [int(c) for c in colors[classIDs[i]]]\n",
    "                \n",
    "                if (X or X_2 ) and area > 2000:\n",
    "                    cv2.rectangle(image, (x, y), (x + w, y + h), (0,0,255), 2)\n",
    "                    roi = croped_image[-size-10:-10, -size-10:-10]\n",
    "                    # Set an index of where the mask is\n",
    "                    roi[np.where(mask)] = 0\n",
    "                    roi += Slow\n",
    "                else:\n",
    "                    cv2.rectangle(image, (x, y), (x + w, y + h), (255,255,255), 2)\n",
    "\n",
    "                text = \"{}: {:.4f}\".format('Person', confidences[i])\n",
    "                cv2.putText(image, text, (x, y - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,0,0), 2)\n",
    "\n",
    "            if(classIDs[i]==2):\n",
    "                # color = [int(c) for c in colors[classIDs[i]]]\n",
    "                if (X or X_2) and area > 2000:\n",
    "                    cv2.rectangle(image, (x, y), (x + w, y + h), (0,0,255), 2)\n",
    "                    roi = croped_image[-size-10:-10, -size-10:-10]\n",
    "                    # Set an index of where the mask is\n",
    "                    roi[np.where(mask)] = 0\n",
    "                    roi += Slow\n",
    "                else:\n",
    "                    cv2.rectangle(image, (x, y), (x + w, y + h), (255,255,255), 2)\n",
    "\n",
    "                text = \"{}: {:.4f}\".format('car', confidences[i])\n",
    "                cv2.putText(image, text, (x, y - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,0,0), 2)\n",
    "\n",
    "    return image\n",
    "\n",
    "\n",
    "def make_prediction(net, layer_names, labels, image, confidence, threshold):\n",
    "    height, width = image.shape[:2]\n",
    "    \n",
    "    # Create a blob and pass it through the model\n",
    "    blob = cv2.dnn.blobFromImage(image, 1 / 255.0, (416, 416), swapRB=True, crop=False)\n",
    "    net.setInput(blob)\n",
    "    outputs = net.forward(layer_names)\n",
    "\n",
    "    # Extract bounding boxes, confidences and classIDs\n",
    "    boxes, confidences, classIDs = extract_boxes_confidences_classids(outputs, confidence, width, height)\n",
    "\n",
    "    # Apply Non-Max Suppression\n",
    "    idxs = cv2.dnn.NMSBoxes(boxes, confidences, confidence, threshold)\n",
    "\n",
    "    return boxes, confidences, classIDs, idxs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def area(x1, y1, x2, y2, x3, y3):\n",
    " \n",
    "    return abs((x1 * (y2 - y3) + x2 * (y3 - y1)\n",
    "                + x3 * (y1 - y2)) / 2.0)\n",
    "\n",
    "def isInside(x1, y1, x2, y2, x3, y3, x, y):\n",
    " \n",
    "    # Calculate area of triangle ABC\n",
    "    A = area (x1, y1, x2, y2, x3, y3)\n",
    " \n",
    "    # Calculate area of triangle PBC\n",
    "    A1 = area (x, y, x2, y2, x3, y3)\n",
    "     \n",
    "    # Calculate area of triangle PAC\n",
    "    A2 = area (x1, y1, x, y, x3, y3)\n",
    "     \n",
    "    # Calculate area of triangle PAB\n",
    "    A3 = area (x1, y1, x2, y2, x, y)\n",
    "     \n",
    "    # Check if sum of A1, A2 and A3\n",
    "    # is same as A\n",
    "    if(A == A1 + A2 + A3):\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video file finished.\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture('project.avi')\n",
    "\n",
    "# Read Slow and resize\n",
    "Slow = cv2.imread(\"SlowDown.png\")\n",
    "size = 100\n",
    "Slow = cv2.resize(Slow, (size, size))\n",
    "# Create a mask of Slow\n",
    "img2gray = cv2.cvtColor(Slow, cv2.COLOR_BGR2GRAY)\n",
    "ret, mask = cv2.threshold(img2gray, 1, 255, cv2.THRESH_BINARY)\n",
    "X = False\n",
    "\n",
    "frame_width = int(cap.get(3))\n",
    "frame_height = int(cap.get(4))\n",
    "\n",
    "out = cv2.VideoWriter('a.webm',cv2.VideoWriter_fourcc(*'DIVX'),15, frameSize= (512,512))\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, image = cap.read()\n",
    "    if not ret:\n",
    "        print('Video file finished.')\n",
    "        break\n",
    "    image = cv2.resize(image,(512,512)) \n",
    "    croped_image = image#[:,120:400]\n",
    "    start_time = time.time()\n",
    "    boxes, confidences, classIDs, idxs = make_prediction(net, layer_names, labels, croped_image, 0.5, 0.3)\n",
    "    end_time = time.time()\n",
    "    # for key,value in \n",
    "    # print(boxes)\n",
    "    croped_image = draw_bounding_boxes(croped_image, boxes, confidences, classIDs, idxs, colors,Slow)\n",
    "    # cv2.putText(img=croped_image, text='FPS: '+str(round(1.0/(end_time-start_time),2)), org=(0, 20), fontFace=cv2.FONT_HERSHEY_TRIPLEX, fontScale=0.5, color=(0, 0, 255),thickness=1)\n",
    "    \n",
    "    # Flip the frame\n",
    "    #croped_image = cv2.flip(croped_image, 1)\n",
    "    # Region of Image (ROI), where we want to insert logo\n",
    "    out.write(croped_image)\n",
    "\n",
    "    cv2.imshow('YOLO Object Detection', croped_image)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b09ec625f77bf4fd762565a912b97636504ad6ec901eb2d0f4cf5a7de23e1ee5"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
